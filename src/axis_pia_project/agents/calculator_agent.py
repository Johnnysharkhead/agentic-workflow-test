from langchain_core.messages import SystemMessage, HumanMessage
from ..config import llm_from_axis 
from ..memory_LLMs_schema import AgentState
from ..tools import dummy_calculator

# Node 2: Calculator Agent
def calculator_agent(state: AgentState) -> AgentState:
    """Perform calculations based on user input and return the answer."""
    
    llm = llm_from_axis
    
    # augment the llm with tools (calculator)
    llm_with_tools = llm.bind_tools([dummy_calculator])
    
    user_input = state["messages"][-1].content # comes from the agent state, which is the original user input(short-term memory)
    
    # Agent makes decision based on the reasoning by augmented LLM
    system_message = """
    Role: You are a mathematical calculation assistant.
    Task: When the user asks a question that requires calculation, you should use the calculator tool to get the answer.
    Remember to use the tool when necessary, and provide a friendly and concise response to the user based on the tool's output.
    """

    # First time to invoke the LLM agent, to see if it will call the tool
    response = llm_with_tools.invoke([
        SystemMessage(content=system_message),
        HumanMessage(content=user_input)
    ])

    
    # Check if the agent decided to call the tool (this is a feature of the augmented LLM, which can call tools when it thinks it's necessary)
    if response.tool_calls:
        
        # for monitoring whether the agent decides to use the tool and what input it gives to the tool
        print("Calculator Agent decided to use the tool with input:", response.tool_calls[0]["args"])
        
        tool_call = response.tool_calls[0]  # only one tool call expected
        tool_result = dummy_calculator.invoke(tool_call["args"])
        
        # Second time to invoke the LLM agent, to generate the final answer based on the tool result
        final_response = llm.invoke([
            SystemMessage(content=system_message), # keep the system message to remind the agent of its role and task
            HumanMessage(content=user_input), # keep the original user input to maintain the context
            response, # the response from the first time invoking, which contains the tool calling decision and can be used by the agent to generate the final answer
            HumanMessage(content=f"Tool result: {tool_result}") # provide the tool result to the agent
        ])
        
        answer = final_response.content
    
    else:
        # no tool calling, directly return the response from the agent
        # this means the final answer is purly generated by the LLM
        answer = llm.invoke([
            SystemMessage(content=system_message),
            HumanMessage(content=user_input)
        ]).content
        
    #print(f"Calculator Agent Result: {answer}")
    
    return {
        **state,
        "final_answer": answer
    }
