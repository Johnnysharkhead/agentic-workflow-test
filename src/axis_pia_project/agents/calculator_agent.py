from langchain_core.messages import SystemMessage, HumanMessage

from axis_pia_project.tools.query_with_itemId import api_query_base_on_itemId
from ..config import llm_from_axis 
from ..memory_LLMs_schema import AgentState
from ..tools import dummy_calculator
from ..tools import api_query_base_on_itemId

# Node 2: Calculator Agent
def calculator_agent(state: AgentState) -> AgentState:
    """Perform calculations based on user input and return the answer."""
    
    llm = llm_from_axis
    
    # augment the llm with tools (calculator)
    llm_with_tools = llm.bind_tools([dummy_calculator, api_query_base_on_itemId])
    
    user_input = state["messages"][-1].content # comes from the agent state, which is the original user input(short-term memory)
    
    # Agent makes decision based on the reasoning by augmented LLM
    system_message = """
    Role: You are a task assignment decision assistant.
    Task: When the user asks a question that requires calculation or query info based on itemId, you should use the appropriate tool to get the answer.
    Remember to use the tool when necessary, and provide a friendly and concise response to the user based on the tool's output.
    """

    # First time to invoke the LLM agent, to see if it will call the tool
    # 第一次调用 LLM → LLM 返回 tool_calls（告诉你它想调哪个工具、传什么参数）
    response = llm_with_tools.invoke([
        SystemMessage(content=system_message),
        HumanMessage(content=user_input)
    ])

    
    # Check if the agent decided to call the tool (this is a feature of the augmented LLM, which can call tools when it thinks it's necessary)
    if response.tool_calls:

        tool_mapping = {
            "dummy_calculator": dummy_calculator,
            "api_query_base_on_itemId": api_query_base_on_itemId
        }
        
     
        """
        LangChain 的 tool_calls 返回的字典结构是这样的：
        {
            "name": "dummy_calculator",        # 工具名（字符串）
            "args": {"expression": "2+3"},     # 参数（字典）
            "id": "call_xxx"                   # 调用ID
        }
        """
        print("Calculator Agent decided to use the tool with input:", response.tool_calls[0]["args"])

        tool_func = tool_mapping.get(response.tool_calls[0]["name"])
           
        # for monitoring whether the agent decides to use the tool and what input it gives to the tool
        print(f"Calculator Agent decided to use the tool: {response.tool_calls[0]['name']}")

        tool_result = tool_func.invoke(response.tool_calls[0]["args"])
        
        # Second time to invoke the LLM agent, to generate the final answer based on the tool result
        final_response = llm.invoke([
            SystemMessage(content=system_message), # keep the system message to remind the agent of its role and task
            HumanMessage(content=user_input), # keep the original user input to maintain the context
            response, # the response from the first time invoking, which contains the tool calling decision and can be used by the agent to generate the final answer
            HumanMessage(content=f" {tool_result}") # provide the tool result to the agent
        ])
        
        answer = final_response.content
    
    else:
        # no tool calling, directly return the response from the agent
        # this means the final answer is purly generated by the LLM
        answer = llm.invoke([
            SystemMessage(content=system_message),
            HumanMessage(content=user_input)
        ]).content
        
    #print(f"Calculator Agent Result: {answer}")
    
    return {
        **state,
        "final_answer": answer
    }
